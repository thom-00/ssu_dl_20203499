{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iv5uhycKxQqJ",
        "outputId": "54897af0-d77b-407b-af0a-e1ad10aa8793"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from transformers import TFRobertaModel\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "tokenizer_save_path = '/content/drive/MyDrive/tokenizer/'\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(tokenizer_save_path)\n",
        "\n",
        "# 데이터 로드\n",
        "file_path = '/content/drive/MyDrive/val_noun_df.csv'\n",
        "model_path_pre = '/content/drive/MyDrive/불용어제거이후모델/rm_stopwrd_base_256_'\n",
        "def remove_nouns(text, nouns):\n",
        "    for noun in nouns:\n",
        "        text = text.replace(noun, '')\n",
        "    return text\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  nouns_list = row['NOUNS'].split('_SEP_')\n",
        "  df.at[index, 'paragraphs'] = remove_nouns(row['paragraphs'], nouns_list)"
      ],
      "metadata": {
        "id": "nW8zDQm8yD5X"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWov3xy0xN1t",
        "outputId": "03d55af4-135b-48d3-c3bd-c1663ac9d161"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 38s 1s/step\n",
            "불용어 제거 후 모델 성능 평가\n",
            "대안제시의 성능\n",
            "MSE: 40.975307834544445, MAE: 4.448691100115203, RMSE: 6.401195812857504\n",
            "======================================\n",
            "21/21 [==============================] - 29s 1s/step\n",
            "불용어 제거 후 모델 성능 평가\n",
            "글짓기의 성능\n",
            "MSE: 45.589908160802786, MAE: 3.9905332569393126, RMSE: 6.752029928903069\n",
            "======================================\n",
            "31/31 [==============================] - 40s 1s/step\n",
            "불용어 제거 후 모델 성능 평가\n",
            "찬성반대의 성능\n",
            "MSE: 47.44617187661635, MAE: 4.468396201491044, RMSE: 6.888118166568889\n",
            "======================================\n",
            "47/47 [==============================] - 60s 1s/step\n",
            "불용어 제거 후 모델 성능 평가\n",
            "주장의 성능\n",
            "MSE: 58.31462836213272, MAE: 5.303009699930387, RMSE: 7.636401532275049\n",
            "======================================\n",
            "58/58 [==============================] - 74s 1s/step\n",
            "불용어 제거 후 모델 성능 평가\n",
            "설명글의 성능\n",
            "MSE: 17.725752766913885, MAE: 3.18753626543037, RMSE: 4.210196286031553\n",
            "======================================\n"
          ]
        }
      ],
      "source": [
        "test_target = ['대안제시', '글짓기', '찬성반대', '주장', '설명글']\n",
        "\n",
        "for target in test_target:\n",
        "\n",
        "  model_path = model_path_pre+f'{target}.h5'  # 모델 경로 지정\n",
        "  model = load_model(model_path, custom_objects={'TFRobertaModel': TFRobertaModel})\n",
        "  df = pd.read_csv(file_path)\n",
        "  df = df[df['class']==target]\n",
        "\n",
        "  paragraphs = df['paragraphs'].values\n",
        "  scores = df['score'].values\n",
        "  max_length = 512\n",
        "  X_ids = np.zeros((len(paragraphs), max_length))\n",
        "  X_mask = np.zeros((len(paragraphs), max_length))\n",
        "\n",
        "  for i, paragraph in enumerate(paragraphs):\n",
        "      tokens = tokenizer.encode_plus(paragraph, max_length=max_length, truncation=True,\n",
        "                                    padding='max_length', add_special_tokens=True,\n",
        "                                    return_tensors='tf')\n",
        "      X_ids[i, :] = tokens['input_ids']\n",
        "      X_mask[i, :] = tokens['attention_mask']\n",
        "\n",
        "  predictions = model.predict([X_ids, X_mask])\n",
        "\n",
        "\n",
        "  mse = mean_squared_error(scores, predictions)\n",
        "  mae = mean_absolute_error(scores, predictions)\n",
        "  rmse = np.sqrt(mse)\n",
        "\n",
        "  print('불용어 제거 후 모델 성능 평가')\n",
        "  print(f'{target}의 성능')\n",
        "  print(f\"MSE: {mse}, MAE: {mae}, RMSE: {rmse}\")\n",
        "  print(f'======================================')"
      ]
    }
  ]
}